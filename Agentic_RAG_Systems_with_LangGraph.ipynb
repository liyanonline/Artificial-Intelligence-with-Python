{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMj3r94lbBRSkeFn0LXlHff",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liyanonline/Artificial-Intelligence-with-Python/blob/master/Agentic_RAG_Systems_with_LangGraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0qh101C1YuW3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af7530c7-a649-4330-d4c4-c7d8226da705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.2.0\n",
            "  Downloading langchain-0.2.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (2.0.38)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (3.11.12)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.2.0)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain-core<0.3.0,>=0.2.0 (from langchain==0.2.0)\n",
            "  Downloading langchain_core-0.2.43-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain==0.2.0)\n",
            "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.2.0)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (2.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (2.32.3)\n",
            "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.2.0)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.2.0)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.2.0)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.0) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.0) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.0) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.0) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.0) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.0) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain==0.2.0) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.2.0)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (1.3.1)\n",
            "Downloading langchain-0.2.0-py3-none-any.whl (973 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.7/973.7 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_core-0.2.43-py3-none-any.whl (397 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.1/397.1 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: tenacity, mypy-extensions, marshmallow, typing-inspect, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.8\n",
            "    Uninstalling langsmith-0.3.8:\n",
            "      Successfully uninstalled langsmith-0.3.8\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.35\n",
            "    Uninstalling langchain-core-0.3.35:\n",
            "      Successfully uninstalled langchain-core-0.3.35\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.6\n",
            "    Uninstalling langchain-text-splitters-0.3.6:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.6\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.18\n",
            "    Uninstalling langchain-0.3.18:\n",
            "      Successfully uninstalled langchain-0.3.18\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-0.2.0 langchain-core-0.2.43 langchain-text-splitters-0.2.4 langsmith-0.1.147 marshmallow-3.26.1 mypy-extensions-1.0.0 tenacity-8.5.0 typing-inspect-0.9.0\n",
            "Collecting langchain-openai==0.1.7\n",
            "  Downloading langchain_openai-0.1.7-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.1.46 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.1.7) (0.2.43)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.1.7) (1.61.1)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.1.7)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (0.1.147)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (2.10.6)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.1.7) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.1.7) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.1.7) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.1.7) (2.3.0)\n",
            "Downloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain-openai\n",
            "Successfully installed langchain-openai-0.1.7 tiktoken-0.9.0\n",
            "Collecting langchain-community==0.2.0\n",
            "  Downloading langchain_community-0.2.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (2.0.38)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (3.11.12)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (0.2.0)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (0.2.43)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (2.32.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.0) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.0) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (0.2.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community==0.2.0) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community==0.2.0) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community==0.2.0) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (1.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.2.0) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain-community==0.2.0) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.0) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (1.3.1)\n",
            "Downloading langchain_community-0.2.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-community\n",
            "Successfully installed langchain-community-0.2.0\n",
            "Collecting langgraph==0.1.1\n",
            "  Downloading langgraph-0.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.2 in /usr/local/lib/python3.11/dist-packages (from langgraph==0.1.1) (0.2.43)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (0.1.147)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (2.10.6)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (4.12.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2->langgraph==0.1.1) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langgraph==0.1.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langgraph==0.1.1) (2.27.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (1.3.1)\n",
            "Downloading langgraph-0.1.1-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.3/87.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langgraph\n",
            "Successfully installed langgraph-0.1.1\n",
            "Collecting langchain-chroma==0.1.1\n",
            "  Downloading langchain_chroma-0.1.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting chromadb<0.6.0,>=0.4.0 (from langchain-chroma==0.1.1)\n",
            "  Downloading chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting fastapi<1,>=0.95.2 (from langchain-chroma==0.1.1)\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.1.40 in /usr/local/lib/python3.11/dist-packages (from langchain-chroma==0.1.1) (0.2.43)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-chroma==0.1.1) (1.26.4)\n",
            "Collecting build>=1.0.3 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (2.10.6)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading posthog-3.14.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.16.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.16.0)\n",
            "Collecting tokenizers<=0.20.3,>=0.13.2 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting pypika>=0.48.9 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.70.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (0.15.1)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading kubernetes-32.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (8.5.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (13.9.4)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi<1,>=0.95.2->langchain-chroma==0.1.1)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma==0.1.1) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma==0.1.1) (0.1.147)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma==0.1.1) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.40->langchain-chroma==0.1.1) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (2.3.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.40->langchain-chroma==0.1.1) (1.0.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (4.25.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.2.18)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (75.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.66.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-util-http==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting importlib-metadata<=8.5.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<=0.20.3,>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (0.28.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (14.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (3.4.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain-chroma==0.1.1) (0.6.1)\n",
            "Downloading langchain_chroma-0.1.1-py3-none-any.whl (8.5 kB)\n",
            "Downloading chromadb-0.5.23-py3-none-any.whl (628 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading kubernetes-32.0.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.30.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.51b0-py3-none-any.whl (7.3 kB)\n",
            "Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.14.1-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
            "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53771 sha256=85b9c125a21136c537787ee4c54bf33470e01146ce1401e11144d7c400c6dc01\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, python-dotenv, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, mmh3, importlib-metadata, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, opentelemetry-api, coloredlogs, build, tokenizers, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb, langchain-chroma\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.16.0\n",
            "    Uninstalling opentelemetry-api-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.16.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.16.0\n",
            "    Uninstalling opentelemetry-sdk-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.48.3 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.23 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.8 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.5.0 kubernetes-32.0.0 langchain-chroma-0.1.1 mmh3-5.1.0 monotonic-1.6 onnxruntime-1.20.1 opentelemetry-api-1.30.0 opentelemetry-exporter-otlp-proto-common-1.30.0 opentelemetry-exporter-otlp-proto-grpc-1.30.0 opentelemetry-instrumentation-0.51b0 opentelemetry-instrumentation-asgi-0.51b0 opentelemetry-instrumentation-fastapi-0.51b0 opentelemetry-proto-1.30.0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 opentelemetry-util-http-0.51b0 overrides-7.7.0 posthog-3.14.1 protobuf-5.29.3 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.0.1 starlette-0.45.3 tokenizers-0.20.3 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              },
              "id": "f0787489e2804f73915b35c9cd746623"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# https://www.analyticsvidhya.com/blog/2024/07/building-agentic-rag-systems-with-langgraph/\n",
        "\n",
        "# A Comprehensive Guide to Building Agentic RAG Systems with LangGraph\n",
        "# Dipanjan (DJ) Sarkar\n",
        "# Last Updated : 24 Dec, 2024\n",
        "\n",
        "!pip install langchain==0.2.0\n",
        "!pip install langchain-openai==0.1.7\n",
        "!pip install langchain-community==0.2.0\n",
        "!pip install langgraph==0.1.1\n",
        "!pip install langchain-chroma==0.1.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "OPENAI_KEY = getpass('Enter Open AI API Key: ')\n",
        "TAVILY_API_KEY = getpass('Enter Tavily Search API Key: ')\n",
        "\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n",
        "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY\n",
        "\n"
      ],
      "metadata": {
        "id": "ehdxdgI6zFfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "# details here: https://openai.com/blog/new-embedding-models-and-api-updates\n",
        "openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')\n"
      ],
      "metadata": {
        "id": "2TS1k1etztmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import json\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "wikipedia_filepath = 'simplewiki-2020-11-01.jsonl.gz'\n",
        "docs = []\n",
        "with gzip.open(wikipedia_filepath, 'rt', encoding='utf8') as fIn:\n",
        "    for line in fIn:\n",
        "        data = json.loads(line.strip())\n",
        "        #Add documents\n",
        "        docs.append({\n",
        "                        'metadata': {\n",
        "                                        'title': data.get('title'),\n",
        "                                        'article_id': data.get('id')\n",
        "                        },\n",
        "                        'data': ' '.join(data.get('paragraphs')[0:3])\n",
        "        # restrict data to first 3 paragraphs to run later modules faster\n",
        "        })\n",
        "# We subset our data to use a subset of wikipedia documents to run things faster\n",
        "docs = [doc for doc in docs for x in ['india']\n",
        "              if x in doc['data'].lower().split()]\n",
        "# Create docs\n",
        "docs = [Document(page_content=doc['data'],\n",
        "                 metadata=doc['metadata']) for doc in docs]\n",
        "# Chunk docs\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=300)\n",
        "chunked_docs = splitter.split_documents(docs)\n",
        "chunked_docs[:3]\n"
      ],
      "metadata": {
        "id": "GVN9UUDgzyoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "# create vector DB of docs and embeddings - takes < 30s on Colab\n",
        "chroma_db = Chroma.from_documents(documents=chunked_docs,\n",
        "                                  collection_name='rag_wikipedia_db',\n",
        "                                  embedding=openai_embed_model,\n",
        "# need to set the distance function to cosine else it uses Euclidean by default\n",
        "# check https://docs.trychroma.com/guides#changing-the-distance-function\n",
        "                                  collection_metadata={\"hnsw:space\": \"cosine\"},\n",
        "                                  persist_directory=\"./wikipedia_db\")\n",
        "\n"
      ],
      "metadata": {
        "id": "KqHsPqVEz4D1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_threshold_retriever = chroma_db.as_retriever(search_type=\"similarity_score_threshold\",\n",
        "                       search_kwargs={\"k\": 3,\n",
        "                       \"score_threshold\": 0.3})\n",
        "We can then test if our retriever is working on some sample queries.\n",
        "query = \"what is the capital of India?\"\n",
        "top3_docs = similarity_threshold_retriever.invoke(query)\n",
        "top3_docs\n",
        "query = \"what is langgraph?\"\n",
        "top3_docs = similarity_threshold_retriever.invoke(query)\n",
        "top3_docs\n"
      ],
      "metadata": {
        "id": "rB8rP7i4z6t8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "# Data model for LLM output format\n",
        "class GradeDocuments(BaseModel):\n",
        "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
        "    binary_score: str = Field(\n",
        "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
        "    )\n",
        "# LLM for grading\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
        "# Prompt template for grading\n",
        "SYS_PROMPT = \"\"\"You are an expert grader assessing relevance of a retrieved document to a user question.\n",
        "                Follow these instructions for grading:\n",
        "                  - If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant.\n",
        "                  - Your grade should be either 'yes' or 'no' to indicate whether the document is relevant to the question or not.\"\"\"\n",
        "\n",
        "grade_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", SYS_PROMPT),\n",
        "        (\"human\", \"\"\"Retrieved document:\n",
        "                     {document}\n",
        "                     User question:\n",
        "                     {question}\n",
        "                  \"\"\"),\n",
        "    ]\n",
        ")\n",
        "# Build grader chain\n",
        "doc_grader = (grade_prompt\n",
        "                  |\n",
        "              structured_llm_grader)\n",
        "\n",
        "query = \"what is the capital of India?\"\n",
        "top3_docs = similarity_threshold_retriever.invoke(query)\n",
        "for doc in top3_docs:\n",
        "    print(doc.page_content)\n",
        "    print('GRADE:', doc_grader.invoke({\"question\": query,\n",
        "                                       \"document\": doc.page_content}))\n",
        "    print()\n",
        "\n"
      ],
      "metadata": {
        "id": "prSD_IEM0Avz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from operator import itemgetter\n",
        "# Create RAG prompt for response generation\n",
        "prompt = \"\"\"You are an assistant for question-answering tasks.\n",
        "            Use the following pieces of retrieved context to answer the question.\n",
        "            If no context is present or if you don't know the answer, just say that you don't know the answer.\n",
        "            Do not make up the answer unless it is there in the provided context.\n",
        "            Give a detailed answer and to the point answer with regard to the question.\n",
        "            Question:\n",
        "            {question}\n",
        "            Context:\n",
        "            {context}\n",
        "            Answer:\n",
        "         \"\"\"\n",
        "prompt_template = ChatPromptTemplate.from_template(prompt)\n",
        "# Initialize connection with GPT-4o\n",
        "chatgpt = ChatOpenAI(model_name='gpt-4o', temperature=0)\n",
        "# Used for separating context docs with new lines\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "# create QA RAG chain\n",
        "qa_rag_chain = (\n",
        "    {\n",
        "        \"context\": (itemgetter('context')\n",
        "                        |\n",
        "                    RunnableLambda(format_docs)),\n",
        "        \"question\": itemgetter('question')\n",
        "    }\n",
        "      |\n",
        "    prompt_template\n",
        "      |\n",
        "    chatgpt\n",
        "      |\n",
        "    StrOutputParser()\n",
        ")\n",
        "\n",
        "query = \"what is the capital of India?\"\n",
        "top3_docs = similarity_threshold_retriever.invoke(query)\n",
        "result = qa_rag_chain.invoke(\n",
        "    {\"context\": top3_docs, \"question\": query}\n",
        ")\n",
        "print(result)\n",
        "\n",
        "query = \"who won the champions league in 2024?\"\n",
        "top3_docs = similarity_threshold_retriever.invoke(query)\n",
        "result = qa_rag_chain.invoke(\n",
        "    {\"context\": top3_docs, \"question\": query}\n",
        ")\n",
        "print(result)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bi5gibuk0G5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM for question rewriting\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "# Prompt template for rewriting\n",
        "SYS_PROMPT = \"\"\"Act as a question re-writer and perform the following task:\n",
        "                 - Convert the following input question to a better version that is optimized for web search.\n",
        "                 - When re-writing, look at the input question and try to reason about the underlying semantic intent / meaning.\n",
        "             \"\"\"\n",
        "re_write_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", SYS_PROMPT),\n",
        "        (\"human\", \"\"\"Here is the initial question:\n",
        "                     {question}\n",
        "                     Formulate an improved question.\n",
        "                  \"\"\",\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create rephraser chain\n",
        "question_rewriter = (re_write_prompt\n",
        "                        |\n",
        "                       llm\n",
        "                        |\n",
        "                     StrOutputParser())\n",
        "\n",
        "query = \"who won the champions league in 2024?\"\n",
        "question_rewriter.invoke({\"question\": query})\n",
        "\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "tv_search = TavilySearchResults(max_results=3, search_depth='advanced',max_tokens=10000)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i5ilsoaS0Qcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "    Attributes:\n",
        "        question: question\n",
        "        generation: LLM response generation\n",
        "        web_search_needed: flag of whether to add web search - yes or no\n",
        "        documents: list of context documents\n",
        "    \"\"\"\n",
        "    question: str\n",
        "    generation: str\n",
        "    web_search_needed: str\n",
        "    documents: List[str]\n",
        "\n",
        "def retrieve(state):\n",
        "    \"\"\"\n",
        "    Retrieve documents\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "    Returns:\n",
        "        state (dict): New key added to state, documents - that contains retrieved context documents\n",
        "    \"\"\"\n",
        "    print(\"---RETRIEVAL FROM VECTOR DB---\")\n",
        "    question = state[\"question\"]\n",
        "    # Retrieval\n",
        "    documents = similarity_threshold_retriever.invoke(question)\n",
        "    return {\"documents\": documents, \"question\": question}\n",
        "\n",
        "def grade_documents(state):\n",
        "    \"\"\"\n",
        "    Determines whether the retrieved documents are relevant to the question\n",
        "    by using an LLM Grader.\n",
        "    If any document are not relevant to question or documents are empty - Web Search needs to be done\n",
        "    If all documents are relevant to question - Web Search is not needed\n",
        "    Helps filtering out irrelevant documents\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "    Returns:\n",
        "        state (dict): Updates documents key with only filtered relevant documents\n",
        "    \"\"\"\n",
        "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "    # Score each doc\n",
        "    filtered_docs = []\n",
        "    web_search_needed = \"No\"\n",
        "    if documents:\n",
        "        for d in documents:\n",
        "            score = doc_grader.invoke(\n",
        "                {\"question\": question, \"document\": d.page_content}\n",
        "            )\n",
        "            grade = score.binary_score\n",
        "            if grade == \"yes\":\n",
        "                print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
        "                filtered_docs.append(d)\n",
        "            else:\n",
        "                print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
        "                web_search_needed = \"Yes\"\n",
        "                continue\n",
        "    else:\n",
        "        print(\"---NO DOCUMENTS RETRIEVED---\")\n",
        "        web_search_needed = \"Yes\"\n",
        "    return {\"documents\": filtered_docs, \"question\": question,\n",
        "            \"web_search_needed\": web_search_needed}\n",
        "\n",
        "def rewrite_query(state):\n",
        "    \"\"\"\n",
        "    Rewrite the query to produce a better question.\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "    Returns:\n",
        "        state (dict): Updates question key with a re-phrased or re-written question\n",
        "    \"\"\"\n",
        "    print(\"---REWRITE QUERY---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "    # Re-write question\n",
        "    better_question = question_rewriter.invoke({\"question\": question})\n",
        "    return {\"documents\": documents, \"question\": better_question}\n",
        "\n",
        "from langchain.schema import Document\n",
        "def web_search(state):\n",
        "    \"\"\"\n",
        "    Web search based on the re-written question.\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "    Returns:\n",
        "        state (dict): Updates documents key with appended web results\n",
        "    \"\"\"\n",
        "    print(\"---WEB SEARCH---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "    # Web search\n",
        "    docs = tv_search.invoke(question)\n",
        "    web_results = \"\\n\\n\".join([d[\"content\"] for d in docs])\n",
        "    web_results = Document(page_content=web_results)\n",
        "    documents.append(web_results)\n",
        "    return {\"documents\": documents, \"question\": question}\n",
        "\n",
        "def generate_answer(state):\n",
        "    \"\"\"\n",
        "    Generate answer from context document using LLM\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "    Returns:\n",
        "        state (dict): New key added to state, generation, that contains LLM generation\n",
        "    \"\"\"\n",
        "    print(\"---GENERATE ANSWER---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "    # RAG generation\n",
        "    generation = qa_rag_chain.invoke({\"context\": documents, \"question\": question})\n",
        "    return {\"documents\": documents, \"question\": question,\n",
        "            \"generation\": generation}\n",
        "\n",
        "def decide_to_generate(state):\n",
        "    \"\"\"\n",
        "    Determines whether to generate an answer, or re-generate a question.\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "    Returns:\n",
        "        str: Binary decision for next node to call\n",
        "    \"\"\"\n",
        "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
        "    web_search_needed = state[\"web_search_needed\"]\n",
        "    if web_search_needed == \"Yes\":\n",
        "        # All documents have been filtered check_relevance\n",
        "        # We will re-generate a new query\n",
        "        print(\"---DECISION: SOME or ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, REWRITE QUERY---\")\n",
        "        return \"rewrite_query\"\n",
        "    else:\n",
        "        # We have relevant documents, so generate answer\n",
        "        print(\"---DECISION: GENERATE RESPONSE---\")\n",
        "        return \"generate_answer\"\n",
        "\n"
      ],
      "metadata": {
        "id": "ha1KkJMX0alK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END, StateGraph\n",
        "agentic_rag = StateGraph(GraphState)\n",
        "# Define the nodes\n",
        "agentic_rag.add_node(\"retrieve\", retrieve)  # retrieve\n",
        "agentic_rag.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
        "agentic_rag.add_node(\"rewrite_query\", rewrite_query)  # transform_query\n",
        "agentic_rag.add_node(\"web_search\", web_search)  # web search\n",
        "agentic_rag.add_node(\"generate_answer\", generate_answer)  # generate answer\n",
        "# Build graph\n",
        "agentic_rag.set_entry_point(\"retrieve\")\n",
        "agentic_rag.add_edge(\"retrieve\", \"grade_documents\")\n",
        "agentic_rag.add_conditional_edges(\n",
        "    \"grade_documents\",\n",
        "    decide_to_generate,\n",
        "    {\"rewrite_query\": \"rewrite_query\", \"generate_answer\": \"generate_answer\"},\n",
        ")\n",
        "agentic_rag.add_edge(\"rewrite_query\", \"web_search\")\n",
        "agentic_rag.add_edge(\"web_search\", \"generate_answer\")\n",
        "agentic_rag.add_edge(\"generate_answer\", END)\n",
        "# Compile\n",
        "agentic_rag = agentic_rag.compile()\n",
        "\n",
        "from IPython.display import Image, display, Markdown\n",
        "display(Image(agentic_rag.get_graph().draw_mermaid_png()))\n",
        "\n",
        "query = \"what is the capital of India?\"\n",
        "response = agentic_rag.invoke({\"question\": query})\n",
        "\n",
        "display(Markdown(response['generation']))\n",
        "\n",
        "query = \"who won the champions league in 2024?\"\n",
        "response = agentic_rag.invoke({\"question\": query})\n",
        "\n",
        "display(Markdown(response['generation']))\n",
        "\n",
        "query = \"Tell me about India\"\n",
        "response = agentic_rag.invoke({\"question\": query})\n",
        "\n",
        "display(Markdown(response['generation']))\n",
        "\n"
      ],
      "metadata": {
        "id": "CPklT5k90sbG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}